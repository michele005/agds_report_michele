---
title: "Report Exercise 8"
author: "Michele Iannuzzo"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
---
# Setup

I load the necessary libraries and read the data frame "hh_fluxes.csv".
Then, I initialize the predictors. Therefore, I use the hh_fluxes data frame and remove the columns I don't need with select() and put a "-" in front of the columns I want to remove.
Finally, I initialize a vector ("preds_all") where I add the selected variables which will be all of my predictor variables and a vector to save all the AIC values ("aic_values"). I will will need this vector for the visualization of my results.

```{r}
#load libraries
library(tidyverse)

#load data
hh_fluxes <- read_csv("../data/hh_fluxes.csv")

#initialize predictors
preds_all <- hh_fluxes |>
  select(-GPP_NT_VUT_REF,
         -siteid,
         -TIMESTAMP) |>
  colnames()

#initialize aic_values vector
aic_values <- c()
```

# Step 1: Set predictors
#### Set the number of predictors to be considered to p = 1.
```{r}
#set number of predictors to p = 1
p <- 1
```

# Step 2: Regression model & R-squared.
#### Fit all regression models with p predictors and compute their R-squared.

First, I specify the model formula. I use a fitting linear model lm() and added it to "model". I further use summary() to extract the R-squared values.
With the function names() I add the names to the values, so the results are better readable.
```{r}
#fit all regression models with p predictors and compute their R-squared
r_squared <- map(preds_all, ~{
  formula <- reformulate(.x, response = "GPP_NT_VUT_REF")
  model <- lm(formula, data = hh_fluxes)
  summary(model)$r.squared
})

#add the names of the R-squared
names(r_squared) <- preds_all

#show the results
r_squared

```

# Step 3: Highest R-squared & its AIC
#### Select the model with p predictors that achieves the highest R-squared (best fitting model) and compute its AIC.

I use the function which.max() to find the highes R-squared value from step 2. Because at this stage p is still 1, I am only looking for one R-squared value. I add this to the best_model_index. Then I take the variables determined in the best_model_index (at this point only 1) from the all of my predictors (preds_all) and save it to best_model_predictors. This new vector (best_model_predictors) will be needed to calculate the best fitting model and its AIC.
After specifying the "best_model_formula" and determining the best fitting model "best_model" I calculate its AIC.
Additionally, I save the best_model_aic to "previous_model_aic" because I will need that later to compare if the new model fits better than the previous one. Because I was able to determine the model with the highest R-squared with p=1 predictor, it is valid to say this is the best fitting model at the time.
```{r}
#find the model with p predictors that achieves the highest R-squared
best_model_index <- which.max(r_squared)
best_model_predictors <- preds_all[best_model_index]

#fit the best model and compute its AIC
best_model_formula <- reformulate(best_model_predictors, response = "GPP_NT_VUT_REF")
best_model <- lm(best_model_formula, data = hh_fluxes)
best_model_aic <- AIC(best_model)

#store the AIC value for the current model
aic_values <- c(aic_values, best_model_aic)

#set best_model_aic as previous_model_aic for step 4
previous_model_aic <- best_model_aic

#print the best model predictors and its AIC
cat("Best model predictors: ", paste(best_model_predictors, collapse = ", "), "\n")
cat("AIC: ", best_model_aic, "\n")
```

# Step 4 & 5: Best fitting model
#### Increment to p + 1. Fit all regression models with p + 1 predictors and compute their R-squared. Select the best fitting model and compute its AIC. If the AIC of the model with p + 1 predictors is poorer than the AIC of the model with p predictors, retain the model with p predictors and quit. You have found the (presumably) optimal model. Otherwise, continue with with step 4.

First, I increment p to p + 1. Then I use a while loop to find the best fitting model for more than one predictor.
The first step of the while loop is to fit all regression models with p + 1 predictors and compute their R-squared. In the first loop this means, I am checking for two predictors. In every loop the sum of predictors will be incremented by 1. After calculating the R-squared values for p + 1 predictors I pick the highest R-squared with which.max like in step 3. Then, I add this new best_model_index to my existing best_model_predictors.
After this selection, I use the same model formula, determine the best_model and calculate its AIC like in step 3.
Before checking, if the new best_model_aic is poorer than the previous_model_aic, I store the new best_model_aic to the existing aic_values. If the best_model_aic is bigger than the previous_model_aic it's worse than the previous_model_aic and therefore the loop will be stopped ("break"). Otherwise, I want to increment p by 1 and restart the loop to find the best fitting model.
```{r}
#set p + 1
p <- p + 1

while (TRUE) {
  #fit all regression models with p+1 predictors and compute their R-squared
  r_squared <- map(preds_all, ~{
    predictors <- c(best_model_predictors, .x)
    formula <- reformulate(predictors, response = "GPP_NT_VUT_REF")
    model <- lm(formula, data = hh_fluxes)
    summary(model)$r.squared
  })
  
  #find the model with p+1 predictors that achieves the highest R-squared
  best_model_index <- which.max(r_squared)
  best_model_predictors <- c(best_model_predictors, preds_all[best_model_index])
  
  #fit the best model with p+1 predictors and compute its AIC
  best_model_formula <- reformulate(best_model_predictors, response = "GPP_NT_VUT_REF")
  best_model <- lm(best_model_formula, data = hh_fluxes)
  best_model_aic <- AIC(best_model)
  
  #store the AIC value for the current model
  aic_values <- c(aic_values, best_model_aic)
  
  #check if the AIC of the model with p+1 predictors is poorer
  if (best_model_aic > previous_model_aic || p == length(preds_all)) {
    break
  } else {
    previous_model_aic <- best_model_aic
    p <- p + 1
  }
}

#print the best model predictors and its AIC
cat("Best model predictors: ", paste(best_model_predictors, collapse = ", "), "\n")
cat("AIC: ", best_model_aic, "\n")

```

# Visualization

In the previous step I stored the aic_values. Now I create a new data frame ("results") of the predictor counts and the AIC values. With a ggplot I visualize how the AIC has evolved with every new iteration with p + 1 predictors.
```{r}
# Create a data frame of predictor count and AIC values
results <- data.frame(predictor_count = 1:length(aic_values), AIC = aic_values)

# Create a plot of AIC values vs. predictor count
ggplot(results, aes(x = predictor_count, y = AIC)) +
  geom_line() +
  geom_point() +
  labs(x = "Number of Predictors", y = "AIC Value") +
  ggtitle("Stepwise Forward Regression: AIC vs. Predictor Count")
```


# Discussion

My results show that the best fitting model is the model with 10 predictors. The visualization shows the AIC values for every additional predictor. At first, the decline is very steep. From one predictor to two, the AIC falls from 77577.87 (see step 3) to 75000. Whereas the difference between 9 and 10 predictors is fairy small.
